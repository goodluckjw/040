import requests
import xml.etree.ElementTree as ET
from urllib.parse import quote
import re

OC = "chetera"
BASE = "http://www.law.go.kr"

def get_law_list_from_api(search_term):
    exact_query = f'\"{search_term}\"'
    encoded_query = quote(exact_query)
    page = 1
    laws = []

    while True:
        url = f"{BASE}/DRF/lawSearch.do?OC={OC}&target=law&type=XML&display=100&page={page}&search=2&knd=A0002&query={encoded_query}"
        res = requests.get(url, timeout=10)
        res.encoding = 'utf-8'
        if res.status_code != 200:
            break

        root = ET.fromstring(res.content)
        for law in root.findall("law"):
            name = law.findtext("ë²•ë ¹ëª…í•œê¸€", "").strip()
            mst = law.findtext("ë²•ë ¹ì¼ë ¨ë²ˆí˜¸", "")
            detail = law.findtext("ë²•ë ¹ìƒì„¸ë§í¬", "")
            full_link = BASE + detail
            laws.append({"ë²•ë ¹ëª…": name, "MST": mst, "URL": full_link})

        if len(root.findall("law")) < 100:
            break
        page += 1

    return laws

def get_law_text_by_mst(mst):
    url = f"{BASE}/DRF/lawService.do?OC={OC}&target=law&MST={mst}&type=XML"
    try:
        res = requests.get(url, timeout=10)
        res.encoding = 'utf-8'
        return res.content if res.status_code == 200 else None
    except:
        return None

def clean(text):
    return re.sub(r"\s+", "", text or "")

def highlight(text, search_term):
    if not text:
        return ""
    return text.replace(search_term, f"<span style='color:red'>{search_term}</span>")

def get_highlighted_articles(mst, search_term):
    from streamlit import session_state as st_state
    if "stop_search" in st_state and st_state.stop_search:
        return ""

    xml_data = get_law_text_by_mst(mst)
    if not xml_data:
        return "âš ï¸ ë³¸ë¬¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    tree = ET.fromstring(xml_data)
    articles = tree.findall(".//ì¡°ë¬¸ë‹¨ìœ„")
    search_term_clean = clean(search_term)
    results = []

    for article in articles:
        if "stop_search" in st_state and st_state.stop_search:
            break

        ì¡°ë‚´ìš© = article.findtext("ì¡°ë¬¸ë‚´ìš©", "") or ""
        í•­ë“¤ = article.findall("í•­")
        include = False
        í•­ì¶œë ¥ë“¤ = []

        for í•­ in í•­ë“¤:
            í•­ë²ˆí˜¸ = í•­.findtext("í•­ë²ˆí˜¸", "").strip()
            í•­ë‚´ìš© = í•­.findtext("í•­ë‚´ìš©", "") or ""
            í˜¸ì¶œë ¥ë“¤ = []

            if search_term_clean in clean(í•­ë‚´ìš©):
                include = True

            for í˜¸ in í•­.findall("í˜¸"):
                í˜¸ë‚´ìš© = í˜¸.findtext("í˜¸ë‚´ìš©", "") or ""
                ëª©ì¶œë ¥ë“¤ = []

                if search_term_clean in clean(í˜¸ë‚´ìš©):
                    include = True

                for ëª© in í˜¸.findall("ëª©"):
                    ëª©ë‚´ìš© = ëª©.findtext("ëª©ë‚´ìš©", "") or ""
                    if search_term_clean in clean(ëª©ë‚´ìš©):
                        include = True
                        ëª©ì¶œë ¥ë“¤.append(f"<div style='text-indent:6em;'>ã†{highlight(ëª©ë‚´ìš©, search_term)}</div>")

                if ëª©ì¶œë ¥ë“¤ or search_term_clean in clean(í˜¸ë‚´ìš©):
                    í˜¸ì¶œë ¥ë“¤.append(f"<div style='text-indent:4em;'>- {highlight(í˜¸ë‚´ìš©, search_term)}</div>" + "".join(ëª©ì¶œë ¥ë“¤))

            í•­ì¤„ = f"<div style='text-indent:2em;'>{highlight(í•­ë‚´ìš©, search_term)}</div>" + "".join(í˜¸ì¶œë ¥ë“¤)
            if í•­ë‚´ìš©.strip() or í˜¸ì¶œë ¥ë“¤:
                í•­ì¶œë ¥ë“¤.append(í•­ì¤„)

        if search_term_clean in clean(ì¡°ë‚´ìš©):
            include = True

        if include:
            output = ""
            if ì¡°ë‚´ìš©.strip():
                output += f"<div>{highlight(ì¡°ë‚´ìš©, search_term)}</div>"
            output += "".join(í•­ì¶œë ¥ë“¤)
            results.append(output)

    return "".join(results) if results else "ğŸ” í•´ë‹¹ ê²€ìƒ‰ì–´ë¥¼ í¬í•¨í•œ ì¡°ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."
